---
layout: page
title: Assignments
desc: "Information of Assignments and Final Project for 2020 Fall UVa CS 4774 Machine Learning"
---

<hr>

### Five assignments (50%)
+ Post in collab 
+ You will receive grading of each HWs within 10 day of each due time. A release email will send to you about the grading. (If you don’t receive such emails in time, please do email to to <br>
[instructors20fall-machinelearningdeep@collab.its.virginia.edu](mailto:instructors20fall-machinelearningdeep@collab.its.virginia.edu).

+ Please submit all extension requests, questions, and late assignments  to <br>
[instructors20fall-machinelearningdeep@collab.its.virginia.edu](mailto:instructors20fall-machinelearningdeep@collab.its.virginia.edu).
 

<table id="datatab3" summary="Five Assignments" border="1">
<tr>
 <h3><b>
  <th>Index</th>
  <th>Assignment</th>
  <th>Out Date</th>
  <th>In Date</th>
  <th>About</th>
  </b>
  </h3>
</tr>
<tr>
  <td>HW1</td>
  <td>Out in Collab </td>
  <td>W2</td>
  <td>W4</td>
  <td>Linear Regression and  Optimization to Code</td>
</tr>
<tr>
  <td>HW2</td>
  <td>TBD</td>
  <td>W4</td>
  <td>W6</td>
  <td>Polynomial, Ridge, Model Selection to implement</td>
</tr>
<tr>
  <td>HW3</td>
  <td>TBD</td>
  <td>W6</td>
  <td>W9</td>
  <td>Deep NN on imaging to implement and to compete  </td>
</tr>
<tr>
  <td>HW4</td>
  <td>TBD</td>
  <td>W9</td>
  <td>W11</td>
  <td> kNN to implement, SVM, and BoostingTrees to compare, to Model select</td>
</tr>
<tr>
  <td>HW5</td>
  <td>TBD</td>
  <td>W12</td>
  <td>W14</td>
  <td>NBC and Deep on Text to implement and compete</td>
</tr>
</table>

<hr>

### About in-class Quizzess (20%)
+ Quizz dates will show on the schedule page
+ Mostly quizzes will be on Mondays
+ Each quizz includes contents we cover in the previous week
+ We will use your top-10 quizzes to calculate the 20%. 

|INDEX     | Quiz |
|------|----------------------------|
| Q0-fake   | [URL](https://forms.gle/B6Rr6NLRS2G5oUbu5) |
| Q1   | [URL](https://forms.gle/K62mXY3cKQAUwQP5A) |
| Q2   | [URL]() |
| Q3   | [URL]() |
| Q4   | [URL]() |
| Q5   | [URL]() |
| Q6   | [URL]() |
| Q7   | [URL]() |
| Q8   | [URL]() |
| Q9   | [URL]() |
| Q10   | [URL]() |
| Q11   | [URL]() |
| Q12   | [URL]() |
| Q-makeup   | [URL]() |



### About Final Project (30%)
+ Each team includes up to four students 

+ By Week3, we will use a google spreadsheet to coordinating team forming and paper bidding. 
+ Please discuss with your fellow classmates, forming potential teams ASAP. 
+ We allow self-selected papers. 
+ Please share questions and concerns to  to <br>
[instructors20fall-machinelearningdeep@collab.its.virginia.edu](mailto:instructors20fall-machinelearningdeep@collab.its.virginia.edu). 

+ You can select a project from three potential types: 
  - a. [Application-Type:] To produce one machine learning project on cutting-edge data applications with health or social impacts
  - b. [Engineering-Type:] Survey and benchmark multiple pytorch library with a shared goal
  - c. [Research-Type:] To Reproduce a cutting-edge machine learning paper, for instance from Top Venues' most cited 2019 papers 
    + Here are the project presentations from 2019-Fall master-level machine learning that I offered. 
    + All were of "research-type": [https://github.com/qiyanjun/deep2reproduce](https://github.com/qiyanjun/deep2reproduce)


+ Each team is required to submit multiple documents for their project
  - 5 Points (Due in Collab at W4): A powerpoint file  summarizing the proposed benchmarking idea / or the proposed application / or the to-reproduced-paper via a template
  - 5 Points (Due in Collab at W6 ): A project proposal  summarizing the concrete project plan 
  - 5 Points (Due in Collab at W12): A iPython Jupyter notebook / or A python code repo to present your team's code, data visualization, and to obtain the results and analysis through step by step code/ cell run. Your team will go through and show the code-run at the final project presentation meeting to the instructors. 
  - 5 Points (in the last week of the semester): A formal presentation to the instructors  
  - 10 Points (in the last week of the semester): A formal report to the instructors , describing your projects: motivation, method, results and insights. 

+ For the iPython Jupyter notebook your team needs to make: 
  - A Jupyter iPython template is shared to help you structure the project code. 
  - Please read the following papers and then make your IPython Jupiter notebook: [Ten Simple Rules for Reproducible Research in Jupyter Notebooks](https://arxiv.org/abs/1810.08055)
   

+ Here is the potential paper / data / library list (TBD): 

|INDEX     |Title  & Link  |Conference, Year|
|------|----------------------------|----------|
Index|Title|Venues |
1|Semi-Supervised StyleGAN for Disentanglement Learning|ICML2020|
2|Dispersed Exponential Family Mixture VAEs for Interpretable Text Generation|ICML2020|
3|Perceptual Generative Autoencoders|ICML2020|
4|Robust Graph Representation Learning via Neural Sparsification|ICML2020|
5|Doubly Stochastic Variational Inference for Neural Processes with Hierarchical Latent Variables|ICML2020|
6|Adaptive Adversarial Multi-task Representation Learning|ICML2020|
7|Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations|ICML2020|
8|Domain Aggregation Networks for Multi-Source Domain Adaptation|ICML2020|
9|Simple and Deep Graph Convolutional Networks|ICM2020|
10|Provable Representation Learning for Imitation Learning via Bi-level Optimization|ICML2020|
11|Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks|ICLR2020|
12|Causal Discovery with Reinforcement Learning|ICLR2020|
13|Improving Generalization in Meta Reinforcement Learning using Learned Objectives|ICLR2020|
14|ES-MAML: Simple Hessian-Free Meta Learning|ICLR2020|
15|Adversarially Robust Representations with Smooth Encoders|ICLR2020|
16|AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty|ICLR2020|
17|Inductive Matrix Completion Based on Graph Neural Networks|ICLR2020|
18|Understanding the Limitations of Variational Mutual Information Estimators|ICLR2020|
19|On Mutual Information Maximization for Representation Learning|ICLR2020|
20|Unsupervised Clustering using Pseudo-semi-supervised Learning|ICLR2020|
21|A Simple Framework for Contrastive Learning of Visual Representations|ICLR2020|
22|Noise-tolerant fair classification|NeurIPS2019|
23|SGD on Neural Networks Learns Functions of Increasing Complexity|NeurIPS2019|
24|On the Fairness of Disentangled Representations|NeurIPS2019|
25|Approximate Inference Turns Deep Networks into Gaussian Processes|NeurIPS2019|
26|"Time Matters in Regularizing Deep Networks: Weight Decay and Data Augmentation Affect Early Learning Dynamics Matter Little Near Convergence"|NeurIPS2019 |
27|Self-Supervised Generalisation with Meta Auxiliary Learning|NeurIPS2019 |
28|GNNExplainer: Generating Explanations for Graph Neural Networks|NeurIPS 2019 |
29|DAG-GNN: DAG Structure Learning with Graph Neural Networks|ICML2019 |
30|Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems |ICML2020 |

