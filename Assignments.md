---
layout: page
title: Assignments
desc: "Information of Assignments and Final Project for 2020 Fall UVa CS 4774 Machine Learning"
---

<hr>

### Five assignments (50%)
+ Post in collab 
+ You will receive grading of each HWs within 10 day of each due time. A release email will send to you about the grading. (If you don’t receive such emails in time, please do email to to <br>
[instructors20fall-machinelearningdeep@collab.its.virginia.edu](mailto:instructors20fall-machinelearningdeep@collab.its.virginia.edu).

+ Please submit all extension requests, questions, and late assignments  to <br>
[instructors20fall-machinelearningdeep@collab.its.virginia.edu](mailto:instructors20fall-machinelearningdeep@collab.its.virginia.edu).
 

<table id="datatab3" summary="Five Assignments" border="1">
<tr>
 <h3><b>
  <th>Index</th>
  <th>Assignment</th>
  <th>Out Date</th>
  <th>In Date</th>
  <th>About</th>
  </b>
  </h3>
</tr>
<tr>
  <td>HW1</td>
  <td>Out in Collab </td>
  <td>W2</td>
  <td>W4</td>
  <td>Linear Regression and  Optimization to Code</td>
</tr>
<tr>
  <td>HW2</td>
  <td>TBD</td>
  <td>W4</td>
  <td>W6</td>
  <td>Polynomial, Ridge, Model Selection to implement</td>
</tr>
<tr>
  <td>HW3</td>
  <td>TBD</td>
  <td>W6</td>
  <td>W9</td>
  <td>Deep NN on imaging to implement and to compete  </td>
</tr>
<tr>
  <td>HW4</td>
  <td>TBD</td>
  <td>W9</td>
  <td>W11</td>
  <td>NBC and Deep on Text to implement and compete</td>
</tr>
<tr>
  <td>HW5</td>
  <td>TBD</td>
  <td>W11</td>
  <td>W13</td>
  <td> kNN to implement, SVM, and BoostingTrees to compare</td>
</tr>
</table>

<hr>

### About in-class Quizzess (20%)
+ Quizz dates will show on the schedule page
+ Mostly quizzes will be on Mondays
+ Each quizz includes contents we cover in the previous week
+ We will use your top-10 quizzes to calculate the 20%. 

|INDEX     | Quiz |
|------|----------------------------|
| Q0-fake   | [URL](https://forms.gle/B6Rr6NLRS2G5oUbu5) |
| Q1   | [URL](https://forms.gle/K62mXY3cKQAUwQP5A) |
| Q2   | [URL]() |
| Q3   | [URL]() |
| Q4   | [URL]() |
| Q5   | [URL]() |
| Q6   | [URL]() |
| Q7   | [URL]() |
| Q8   | [URL]() |
| Q9   | [URL]() |
| Q10   | [URL]() |
| Q11   | [URL]() |
| Q12   | [URL]() |
| Q-makeup   | [URL]() |


### About in-class flip recital sessions 
+ Starting from Week8, we shift  

|INDEX     | Content for Flipped Recital Sessions |
|------|----------------------------|
| 1013 W8   | deep learning library  |
| 1015  W8   | project plan checkup |
| 1020  W9   | HW1 + HW2 discussions |
| 1022  W9   | Quiz 1-5 discussions |
| 1027  W10   | HW3 discussions |
| 1029  W10   | Slides W9-10 discussions |
| 1103  W11   | Invited speaker RLGym|
| 1105  W11   | Invited speaker TextAttack |
| 1110  W12   |  W11-12 Slides discussions |
| 1112  W12   | project midreport checkup |
| 1117  W13   |  HW3, HW4 discussions  |
| 1119  W13   | Quiz 6-11 discussions +  W13 slides discussions |
| 1124  W14  |  Final Project Presentations  |
| 1126  W14  |  Final Project Presentations  |



### About Final Project (30%)
+ Each team includes up to four students 

+ By Week4, we will use a google spreadsheet to coordinating team forming and project bidding. 
+ Please discuss with your fellow classmates, forming potential teams ASAP. 
+ We allow self-selected papers; libraries; but not close-domain datasets. 
+ Please share questions and concerns to  to <br>
[instructors20fall-machinelearningdeep@collab.its.virginia.edu](mailto:instructors20fall-machinelearningdeep@collab.its.virginia.edu). 

+ You can select a project from three potential types: 
  - a. [Application-Type:] To produce one machine learning project on cutting-edge data applications with health or social impacts
  - b. [Engineering-Type:] Survey and benchmark multiple pytorch library with a shared goal
  - c. [Research-Type:] To Reproduce a cutting-edge machine learning paper, for instance from Top Venues' most cited 2019 papers 
    + Here are the project presentations from 2019-Fall master-level machine learning that I offered. 
    + All were of "research-type": [https://github.com/qiyanjun/deep2reproduce](https://github.com/Qdata4Capstone/course19-deep2reproduce)


+ Each team is required to submit multiple documents for their project
  - 5 Points (Due in Collab at W7): A powerpoint file  summarizing the proposed benchmarking idea / or the proposed application / or the to-reproduced-paper via a template
  - 5 Points (Due in Collab at W10 ): A project proposal report summarizing the concrete project plan 
  - 5 Points (Due in Collab in the last week of the semester): A iPython Jupyter notebook / or A python code repo to present your team's code, data visualization, and to obtain the results and analysis through step by step code/ cell run. Your team will go through and show the code-run at the final project presentation meeting to the instructors. 
  - 5 Points (in the last week of the semester): A formal presentation to the instructors  
  - 10 Points (Due in Collab  in the last week of the semester): A formal report to the instructors , describing your projects: motivation, method, results and insights. 

+ For the iPython Jupyter notebook your team needs to make: 
  - A Jupyter iPython template is shared to help you structure the project code. 
  - Please read the following papers and then make your IPython Jupiter notebook: [Ten Simple Rules for Reproducible Research in Jupyter Notebooks](https://arxiv.org/abs/1810.08055)
   

+ Here is a list of the potential ideas (chunking into three types: (1) replicating paper (2) good applications on  COVID19 datasets, and (3) researching and benchmarking pytorch libraries.):  

|INDEX     |Title  & Link  |Conference, Year|
|--:|:--  | :-: |
|  |    |    |
|  | ***COVID19 Data Hub for b. [Application-Type]***    |    |
| Hub1  |  COVID19 in Kaggle [https://www.kaggle.com/search?q=COVID](https://www.kaggle.com/search?q=COVID) |  2020  |
| Hub2 |  COVID19 in NCBI [https://www.ncbi.nlm.nih.gov/sars-cov-2/](https://www.ncbi.nlm.nih.gov/sars-cov-2/) |  2020  |
| Hub3  |  COVID19 Data [https://datasets.coronawhy.org](https://datasets.coronawhy.org) |2020  |
|   | <img src="{{site.baseurl}}/public/covidData.png">  |  2020  |
|  |    |    |
|  | ***Pytorch Library Investigation for b. [Engineering-Type]***    |    |
| Hub | [https://paperswithcode.com/methods](https://paperswithcode.com/methods)   |  2020   |
| 1 |  to interpret deep NLP models: [LIT](https://github.com/PAIR-code/lit)  |  2020  |
| 1 |  to interpret deep general models: [Captum](https://captum.ai/)  |  2020  |
| 2 | to attack deep NLP models [textAttack](https://github.com/QData/TextAttack)  |  2020  |
| 3|to benchmark adversarial attacks: [Here](https://paperswithcode.com/task/adversarial-attack) ||
|4| Hyperparameter Optimization with PyTorch’s Ecosystem Tools [Here](https://medium.com/pytorch/accelerate-your-hyperparameter-optimization-with-pytorchs-ecosystem-tools-bc17001b9a49) ||
| 5| Deep Probabilistic Programming: [Pyro](https://github.com/pyro-ppl/pyro) ||
|  more | <img src="{{site.baseurl}}/public/trend.png">   |  2020  |
|  |    |    |
|  | ***Papers for c. [Research-Type]***    |    |
1|Semi-Supervised StyleGAN for Disentanglement Learning|ICML2020|
2|Dispersed Exponential Family Mixture VAEs for Interpretable Text Generation|ICML2020|
3|Perceptual Generative Autoencoders|ICML2020|
4|Robust Graph Representation Learning via Neural Sparsification|ICML2020|
5|Doubly Stochastic Variational Inference for Neural Processes with Hierarchical Latent Variables|ICML2020|
6|Adaptive Adversarial Multi-task Representation Learning|ICML2020|
7|Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations|ICML2020|
8|Domain Aggregation Networks for Multi-Source Domain Adaptation|ICML2020|
9|Simple and Deep Graph Convolutional Networks|ICM2020|
10|Provable Representation Learning for Imitation Learning via Bi-level Optimization|ICML2020|
11|Robust And Interpretable Blind Image Denoising Via Bias-Free Convolutional Neural Networks|ICLR2020|
12|Causal Discovery with Reinforcement Learning|ICLR2020|
13|Improving Generalization in Meta Reinforcement Learning using Learned Objectives|ICLR2020|
14|ES-MAML: Simple Hessian-Free Meta Learning|ICLR2020|
15|Adversarially Robust Representations with Smooth Encoders|ICLR2020|
16|AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty|ICLR2020|
17|Inductive Matrix Completion Based on Graph Neural Networks|ICLR2020|
18|Understanding the Limitations of Variational Mutual Information Estimators|ICLR2020|
19|On Mutual Information Maximization for Representation Learning|ICLR2020|
20|Unsupervised Clustering using Pseudo-semi-supervised Learning|ICLR2020|
21|A Simple Framework for Contrastive Learning of Visual Representations|ICLR2020|
22|Noise-tolerant fair classification|NeurIPS2019|
23|SGD on Neural Networks Learns Functions of Increasing Complexity|NeurIPS2019|
24|On the Fairness of Disentangled Representations|NeurIPS2019|
25|Approximate Inference Turns Deep Networks into Gaussian Processes|NeurIPS2019|
26|"Time Matters in Regularizing Deep Networks: Weight Decay and Data Augmentation Affect Early Learning Dynamics Matter Little Near Convergence"|NeurIPS2019 |
27|Self-Supervised Generalisation with Meta Auxiliary Learning|NeurIPS2019 |
28|GNNExplainer: Generating Explanations for Graph Neural Networks|NeurIPS 2019 |
29|DAG-GNN: DAG Structure Learning with Graph Neural Networks|ICML2019 |
30|Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems |ICML2020 |

