---
layout: post
title: Recent deep learning on Text
lecture: S3-deepNNtext
lectureVersion: current
video: <a href="https://youtu.be/iTgy525nBq4">M1</a> + <a href="https://youtu.be/w22S24kFMmA">M2</a> +   <a href="https://youtu.be/5UGmLbAvUH0">M3</a>  
notes: <a href="https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb">Keras Notebook on DNN text </a> 
categories: 1D (Text)
tags:
- Nonlinear
- Deep
- Discriminative
- 4Unsupervised
- Generative
---


In this lecture, we cover: 
- What is NLP?
- Typical NLP tasks / Challenges / Pipeline
- f() on natural language
  + Before Deep NLP (Pre 2012) • (BOW / LSI / Topic Modeling LDA )
  + Word2Vec (2013-2016) • (GloVe/ FastText)
  + Recurrent NN (2014-2016) • LSTM
  + Seq2Seq
  + Attention 
  + Self-Attention (2016 – now )
  + Transformer (attention only Seq2Seq)
  + BERT / RoBERTa/ XLNet/ GPT-2 / ...
 